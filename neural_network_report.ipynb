{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-fZWYiIUhTY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Purpose:***\n",
        "The purpose of this analysis is to create a model that can effectively predict whether a candidate will have success in their field and if they are able to effectively use the funding the organization provides.\n",
        "\n",
        "***Results:***\n",
        "**Data Processing**\n",
        "\n",
        "1.) The variables the model is targeting are the APPLICATION_TYPES from the applicants and the CLASSIFICATION of those types.\n",
        "\n",
        "2.) The features for the model (aka what the model is trying to predict), is the IS_SUCCESSFUL column, which shows if the applicant was able to use the funding provided effectively.\n",
        "\n",
        "3.) We removed the columns for EIN and NAME, as they were not necessary for the data analysis.\n",
        "\n",
        "**Compiling, Training, and Evaluating the Model**\n",
        "\n",
        "1.) For this model we used 2 hidden layers and 1 output layer. It took a lot of trial and error, but we were able to determine that 80 neurons for the first layer and 30 neurons for the second layer were optimal. The final accuracy is then measured to be 0.72, which is optimal.\n",
        "\n",
        "2.) The steps taken to increase the model's performance are: first, using pd.get_dummies to convert the data into binaries (for better reading of the model). The second is adding more layers when optimizing the model.\n",
        "\n",
        "**Conclusion: **the model accurately predicts the success of the applicants by 72.58% and 0.56% of data was lost during the optimization. To better improve the model, I would recommend adding to the training data provided and also to try a different optimization algorithm."
      ],
      "metadata": {
        "id": "3kY2uH40UiSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7B3h0UzlUhsg"
      }
    }
  ]
}